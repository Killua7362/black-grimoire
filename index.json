[{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901271,"size":581,"blocks":8,"atimeMs":1691913950674.2383,"mtimeMs":1691913950411.209,"ctimeMs":1691913950411.209,"birthtimeMs":1691913950411.1729,"atime":"2023-08-13T08:05:50.674Z","mtime":"2023-08-13T08:05:50.411Z","ctime":"2023-08-13T08:05:50.411Z","birthtime":"2023-08-13T08:05:50.411Z"},"slug":"notes/killua brain/CS/Concepts/Hashmap","content":"# Why Hashmap takes constant look time\n\n## Load Factor \n\tIt is the measure of how much size is left in hashmap before rehashes and doubles the size. \n\tIf the initial capacity is greater than \n\t\n\t$maximum\\ number\\ of\\ begining\\ elements/loadfactor$ \n\n\tthen there wont be rehashing in future\n\tSo low load factor means more hashing in future so no more collissions but more lookups.\n\tHashmap creates buckets that means every element is unique so computer knows where that element is exactly!\n\tBut sometime bad hashmap means all elments in single bucket and not constant time lookup\n\n\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901272,"size":75,"blocks":8,"atimeMs":1691913950743.334,"mtimeMs":1691913950411.263,"ctimeMs":1691913950411.263,"birthtimeMs":1691913950411.233,"atime":"2023-08-13T08:05:50.743Z","mtime":"2023-08-13T08:05:50.411Z","ctime":"2023-08-13T08:05:50.411Z","birthtime":"2023-08-13T08:05:50.411Z"},"slug":"notes/killua brain/CS/Concepts/testing","content":"\n\ni am gonna take this yayy\n[[Hashmap]]","frontmatter":{"title":"testing in here only"}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901275,"size":287,"blocks":8,"atimeMs":1691913950661.5432,"mtimeMs":1691913950411.4116,"ctimeMs":1691913950411.4116,"birthtimeMs":1691913950411.3794,"atime":"2023-08-13T08:05:50.662Z","mtime":"2023-08-13T08:05:50.411Z","ctime":"2023-08-13T08:05:50.411Z","birthtime":"2023-08-13T08:05:50.411Z"},"slug":"notes/killua brain/CS/DSA/NeetCode","content":"```ad-abstract\ntitle: Arrays\ncollapse: open\n```\n- [[contains_duplicate]]\n- [[valid_anagram]]\n- [[two_sum]]\n- [[group_anagrams]]\n- [[k_frequent_elements]]\n- [[product_of_array_except_self]]\n- [[sudoku]]\n- [[longest_sequense_length]]\n\n```ad-abstract\ntitle: Two Pointers\ncollapse: open\n```\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901278,"size":479,"blocks":8,"atimeMs":1691913950906.783,"mtimeMs":1691913950411.5776,"ctimeMs":1691913950411.5776,"birthtimeMs":1691913950411.5393,"atime":"2023-08-13T08:05:50.907Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/3sum","content":"\n\nnums = [-1,0,1,2,-1,-4]\nres = []\nnums.sort()\n\nfor i, a in enumerate(nums):\n    if i > 0 and a == nums[i - 1]:\n        continue\n    \n    l, r = i + 1, len(nums) - 1\n    while l < r:\n        threeSum = a + nums[l] + nums[r]\n        if threeSum > 0:\n            r -= 1\n        elif threeSum < 0:\n            l += 1\n        else:\n            res.append([a, nums[l], nums[r]])\n            l += 1\n            while nums[l] == nums[l - 1] and l < r:\n                l += 1\nprint(res)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901279,"size":251,"blocks":8,"atimeMs":1691913950712.6228,"mtimeMs":1691913950411.6418,"ctimeMs":1691913950411.6418,"birthtimeMs":1691913950411.6055,"atime":"2023-08-13T08:05:50.713Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/area_array","content":"def area(i,j):\n    return (min(array[i],array[j]))*(j-i)\n\n\narray = [0,1,0,2,1,0,1,3,2,1,2,1]\nmaxarea = 0\ni=0\nj=len(array)-1\nwhile(i<j):\n    maxarea=max(maxarea,area(i,j))\n    if array[i]>array[j]:\n        j=j-1\n    else:\n        i=i+1\n\nprint(maxarea)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901280,"size":92,"blocks":8,"atimeMs":1691913950719.5535,"mtimeMs":1691913950411.699,"ctimeMs":1691913950411.699,"birthtimeMs":1691913950411.667,"atime":"2023-08-13T08:05:50.720Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/contains_duplicate","content":"hashmap = []\n\nfor n in nums:\n    if n in hashmap:\n        return True\n    hashmap.append(n)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901281,"size":52,"blocks":8,"atimeMs":1691913950923.2896,"mtimeMs":1691913950411.7544,"ctimeMs":1691913950411.7544,"birthtimeMs":1691913950411.7227,"atime":"2023-08-13T08:05:50.923Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/encode_decode","content":"I\narray = [\"lint\",\"code\",\"love\",\"you\"]\nprint(array)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901282,"size":572,"blocks":8,"atimeMs":1691913950715.3154,"mtimeMs":1691913950411.814,"ctimeMs":1691913950411.814,"birthtimeMs":1691913950411.7788,"atime":"2023-08-13T08:05:50.715Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/group_anagrams","content":"from collections import defaultdict\nstrs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\n\n#we can create hashmap with count of alphabets as key and anagrams group as value\n\nhashmap = defaultdict(list)#if count doesnt exist first tiem\n\nfor i,n in enumerate(strs): \n    lists = [0]*26 #there are 26 english alphabets from a...z\n\n    for count in n:\n        lists[ord(count)-ord(\"a\")]+=1 #getting ascii value of string elments\n\n    hashmap[tuple(lists)].append(n) #python cant have list as a key so using tuple\n\nfor i,n in hashmap.items(): #used to print key,value pair\n    print(n)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901283,"size":394,"blocks":8,"atimeMs":1691913950739.3064,"mtimeMs":1691913950411.877,"ctimeMs":1691913950411.877,"birthtimeMs":1691913950411.8389,"atime":"2023-08-13T08:05:50.739Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/k_frequent_elements","content":"nums = [1,1,1,2,2,3]\nk = 2\n\ncount = {}\n\nfor i in nums:\n    count[i]= 1+count.get(i,0)\n#now we can count numbers and  sort based on vlaues in dict or we can use heap and pop k elements\n\n\n#using bucket sort\n# it will be like index is number of time elments occur\nfreq = [[] for i in range(len(nums)+1)] #elments which will occur times\nfor n,c in count.items():\n    freq[c].append(n)\n\nprint(freq)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901284,"size":327,"blocks":8,"atimeMs":1691913950904.79,"mtimeMs":1691913950411.944,"ctimeMs":1691913950411.944,"birthtimeMs":1691913950411.9043,"atime":"2023-08-13T08:05:50.905Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/longest_sequense_length","content":"# we can solve this by checking if there is left elment\n# then it is a starting point\n\n\n```\nnumSet = set(nums)\nlongest = 0\n\nfor n in nums:\n    if n-1 not in numSet:\n        length = 0\n        while n+length in numSet:\n            length+=1\n        longest = max(longest,length)\n\n```\n\n\n/* \nset takes o(n) for every operation \n*/","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901285,"size":261,"blocks":8,"atimeMs":1691913950745.694,"mtimeMs":1691913950412.0051,"ctimeMs":1691913950412.0051,"birthtimeMs":1691913950411.9717,"atime":"2023-08-13T08:05:50.746Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/product_of_array_except_self","content":"array = [1,2,3,4]\nresult =[1 for i in range(len(array))]\n\nprefix = 1\n\nfor i in range(len(array)):\n    result[i] = prefix\n    prefix = prefix*array[i]\n\npostfix =1\nfor i in range(len(array)-1,-1,-1):\n    result[i] *= postfix\n    postfix*=array[i]\n\n\nprint(result)\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901286,"size":428,"blocks":8,"atimeMs":1691913950746.4866,"mtimeMs":1691913950412.0706,"ctimeMs":1691913950412.0706,"birthtimeMs":1691913950412.0342,"atime":"2023-08-13T08:05:50.746Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/sudoku","content":"board = []\ncols = collections.defaultdict(set)\nrows = collections.defaultdict(set)\nsquares = collections.defaultdict(set)\n\nfor r in range(9):\n    for c in range(9):\n        if(board[r][c] in cols[c] or\n                board[r][c] in rows[r]or\n                board[r][c] in squares[(r//3,c//3)]):\n            print(\"bad board\")\n    cols[c].add(board[r][c])\n    rows[r].add(board[r][c])\n    squares[(r//3,c//3)].add(board[r][c])\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901287,"size":27,"blocks":8,"atimeMs":1691913950762.599,"mtimeMs":1691913950412.1304,"ctimeMs":1691913950412.1304,"birthtimeMs":1691913950412.099,"atime":"2023-08-13T08:05:50.763Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/trapping_rain_water","content":"array =[1,8,6,2,5,4,8,3,7]\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901288,"size":162,"blocks":8,"atimeMs":1691913950762.3113,"mtimeMs":1691913950412.1943,"ctimeMs":1691913950412.1943,"birthtimeMs":1691913950412.1587,"atime":"2023-08-13T08:05:50.762Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/two_sum","content":"array = [2,7,11,15]\ntarget = 9\n\nhashmap = {}\n\nfor i,n in enumerate(array):\n    if target-i in hashmap:\n        print(\"yes\")\n        break\n    hashmap[array[i]]=i\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901289,"size":304,"blocks":8,"atimeMs":1691913950760.1719,"mtimeMs":1691913950412.2563,"ctimeMs":1691913950412.2563,"birthtimeMs":1691913950412.2195,"atime":"2023-08-13T08:05:50.760Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/valid_anagram","content":"s=\"anagram\"\nt=\"nagaram\"\n\ndef cheq_anagram(s,t):\n    countS, countT = {},{}\n    for i in range(len(s)):\n        countS[s[i]]=1+countS.get(s[i],0)\n        countT[t[i]]=1+countT.get(t[i],0)\n\n    for i in countS:\n        if countS[i] != countS.get(i,0):\n            print(\"not a anagram\")\n\n\n#or we can do s\n\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901290,"size":0,"blocks":0,"atimeMs":1691913950412.2803,"mtimeMs":1691913950412.2803,"ctimeMs":1691913950412.2803,"birthtimeMs":1691913950412.2803,"atime":"2023-08-13T08:05:50.412Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/DSA/problems/valid_palindrome","content":"","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901292,"size":2017,"blocks":8,"atimeMs":1691913950897.27,"mtimeMs":1691913950412.3938,"ctimeMs":1691913950412.3938,"birthtimeMs":1691913950412.343,"atime":"2023-08-13T08:05:50.897Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/Internship/Journal","content":"Sequence of accounts\nAkshay Bhat\nAkshay(college account)\nKillua\n\n* Trial 33\n\t* Seq len:512\n\t* batch:8\n\t* using nothing but 768 dense with 0.2 max norm\n\t* using dropout of 0.5 for every layer\n\t* using last 4 layers\n\t* using constant learning rate 10%\n\t* Results\n\t\t* Val_loss is higher so overfitting\n\t\t* after 3rd epoch still loss decreasing\n* Trial 34\n\t* Using only last layer\n\t* splitted 768 dense to two 128 dense with 0.5 dropout between and 3 max norm \n\t* training only on last hidden layer\n\t\t* Results\n\t\t\t* Unknown fit yayyy\n\t\t\t* train accuracy>val accruacy\n\t\t\t* so might be dropout problem\n* Trial 35\n\t* batch from 8->16\n\t* Results\n\t\t* Still underfits yayyyy\n* Trial 36\n\t* 16->8 batch\n\t* Remove one dense and dropout layer\n\t\t* Result \n\t\t\t* I call this litttttle overfitting no?\n\t\t\t* ![[trail-36.png]] \n* Trial 37\n\t* back to 16 batch\n\t* changed to 0.1 for all layers between bert layers\n\t* tooooo much overfitting ;(\n* Trial 38\n\t* Back to 0.5 :( drops\n\t* Back to 8 batch(didn't make any difference so...)\n\t* added that dense layer back\n\t* seems to underfit\n\t\t* Results\n\t\t\t* Yayyy underfitting\n* Trial 38\n\t* removed one dense layer\n\t* added global average pooling\n\t\t* Result \n\t\t\t* Overfits\n* Trial 39\n\t* added globalmax pool Back\n\t* Someting happend\n\t\t* result\n\t\t\t* ![[trial-39.png]]\n* Trial 40\n\t* Using globalavg pool\n\t*  0.1 for dropout inside transformer\n\t* ooooverfitting\n* Trial 41\n\t* Using 0.5 dropout only\n\t* overfitting\n* Trial 42\n\t* activation ->dropout->max norm \n\t* not meeting\n\t* result\n\t\t* ![[trial 42.png]]\n* Trial 43\n\t* started using globalmax pool\n\t* drop(64)->dense(0.3)->activation tanh->drop(64)->dense(2)\n\t* Results\n\t\t* ![[trial43.png]]\n* Trial 44\n\t* added leaky relu and l2 regularize for dense layer\n* Trial 45\n\t* Using 256 seq len\n\t* using  max norm with one layer and one dropout layer\n\t* 0.5 dropout for every layer\n\t* batch stays 8\n* Trial 46\n\t* Very light cleaning with no augmentatino\n\t* 256 seq len and batch size 8\n\t* flatten->dense(128)with maxnorm 3 and dropouut 0.5\n\t* lr=2e-5\n\t* ","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901293,"size":321,"blocks":8,"atimeMs":1691913950909.9827,"mtimeMs":1691913950412.4597,"ctimeMs":1691913950412.4597,"birthtimeMs":1691913950412.423,"atime":"2023-08-13T08:05:50.910Z","mtime":"2023-08-13T08:05:50.412Z","ctime":"2023-08-13T08:05:50.412Z","birthtime":"2023-08-13T08:05:50.412Z"},"slug":"notes/killua brain/CS/Internship/Notes","content":"1.  Underfitting – Validation and training error high\n2.  Overfitting – Validation error is high, training error low\n3.  Good fit – Validation error low, slightly higher than the training error\n4.  Unknown fit - Validation error low, training error 'high'\n\n```\nLinear (out=1000-D)\nReLU\nBatchNorm\nDropout (0.25)\n```\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901300,"size":1385,"blocks":8,"atimeMs":1691913950926.9521,"mtimeMs":1691913950413.3796,"ctimeMs":1691913950413.3796,"birthtimeMs":1691913950413.341,"atime":"2023-08-13T08:05:50.927Z","mtime":"2023-08-13T08:05:50.413Z","ctime":"2023-08-13T08:05:50.413Z","birthtime":"2023-08-13T08:05:50.413Z"},"slug":"notes/killua brain/CS/Machine learning/Basic QnA","content":"\nTARGET DECK: Machine learning\n\nwhat is Imputation [[flashcard]]\nIt is method of filling missing data \n<!--ID: 1651239192531-->\n\nIf data is missed complete at the random {do pairwise delete}\n^1651241841406\n<!--ID: 1651239192539-->\n\nWhat is Nominal Variable [[flashcard]] \ndata is independant in feature\n<!--ID: 1651240655653-->\n\nOrdinal Var [[flashcard]] \n Datas are dependant\n<!--ID: 1651240655664-->\n\n\nDummy variable trap [[flashcard]] \nMulticollinearity occuring when there is number of encoded column = number of types of feature\nexample\nMale  1 0\nFemale 0 1 which inturn are identical\nso to avoid this we can use cateories-1 dummy va\nr\n<!--ID: 1651241845884-->\n\npipeline [[flashcard]] \nIt combines multiple transformer,feature scaler etc. then Feature union helps to combine pipeline\n<!--ID: 1651377601869-->\n\n\nk-fold cross validation [[flashcard]] \nIt is used to run same dataset multiple time random set. to avoid overfitting of data\n<!--ID: 1651377601880-->\n\n\nGrid search [[flashcard]] \nIt is used to get test all hyperparameters from dict\n<!--ID: 1651377601885-->\n\n\nConfusion matrix [[flashcard]] \nNumber of time class a considered as class b\n<!--ID: 1651377601887-->\n\ndifference between batch gradient descent and stochastic gradient design [[flashcard]] \nfinding gradient design for whole data vs some batch of data","frontmatter":{"cards-deck":"killua brain::Coding::Machine learning"}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901301,"size":390,"blocks":8,"atimeMs":1691913950926.498,"mtimeMs":1691913950413.4424,"ctimeMs":1691913950413.4424,"birthtimeMs":1691913950413.4077,"atime":"2023-08-13T08:05:50.926Z","mtime":"2023-08-13T08:05:50.413Z","ctime":"2023-08-13T08:05:50.413Z","birthtime":"2023-08-13T08:05:50.413Z"},"slug":"notes/killua brain/CS/Machine learning/Encoding","content":"# Encoding\nIt is used to convert words to numerical value\n\nTypes of Encoding:\n- Ordinal Encoding\n\tIt is used to create relationship\n- One-Hot Encoding\n\tIt is used to convert numbers into 1 or 0 tables but more the type of var more the column so more complexity\n- Dummy Var Encoding\n\tIt is same as one hot encoding but ignores last column\n- Lable Encoder\n\tIt is for encoding yes or no lable\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901302,"size":201,"blocks":8,"atimeMs":1691913950934.194,"mtimeMs":1691913950413.5068,"ctimeMs":1691913950413.5068,"birthtimeMs":1691913950413.4668,"atime":"2023-08-13T08:05:50.934Z","mtime":"2023-08-13T08:05:50.414Z","ctime":"2023-08-13T08:05:50.414Z","birthtime":"2023-08-13T08:05:50.413Z"},"slug":"notes/killua brain/CS/Machine learning/Feature Scaling","content":"# Feature Scaling\nIt allows to put every data on same scale to avoid domination\n\nType of Feature Scaing:\n- Normalization - moving it from 0 to 1\n- Standardization\n\n> Don't apply these for encoded var\n\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901304,"size":0,"blocks":0,"atimeMs":1691913950413.5637,"mtimeMs":1691913950413.5637,"ctimeMs":1691913950413.5637,"birthtimeMs":1691913950413.5637,"atime":"2023-08-13T08:05:50.414Z","mtime":"2023-08-13T08:05:50.414Z","ctime":"2023-08-13T08:05:50.414Z","birthtime":"2023-08-13T08:05:50.414Z"},"slug":"notes/killua brain/CS/Machine learning/Regression/Linear Regression","content":"","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901306,"size":352,"blocks":8,"atimeMs":1691913950931.2375,"mtimeMs":1691913950413.6748,"ctimeMs":1691913950413.6748,"birthtimeMs":1691913950413.6392,"atime":"2023-08-13T08:05:50.931Z","mtime":"2023-08-13T08:05:50.414Z","ctime":"2023-08-13T08:05:50.414Z","birthtime":"2023-08-13T08:05:50.414Z"},"slug":"notes/killua brain/CS/Python/Arrays","content":"- hashmap.get(index,default value)\n\t- this is used to deal with keyerror which is used when index is not in hashmap\n- ascii value of variable a is ord(a)\n- In python list cannot be keys \n- we can use defaultdict if there we need to initiate empty list which can take value which is not in it too\n\t- defaultdict(list,lambda:0) list with initial value 0\n","frontmatter":{}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901308,"size":385,"blocks":8,"atimeMs":1691913950935.9114,"mtimeMs":1691913950413.7725,"ctimeMs":1691913950413.7725,"birthtimeMs":1691913950413.7375,"atime":"2023-08-13T08:05:50.936Z","mtime":"2023-08-13T08:05:50.414Z","ctime":"2023-08-13T08:05:50.414Z","birthtime":"2023-08-13T08:05:50.414Z"},"slug":"notes/killua brain/CS/Rust/Basic Rust","content":"\n# Cargo\n- you have to run cargo new to create new crate\n- cargo build to build src/main.rs file\n- ./target/debug/foldername to run it\n- cargo run = build+run\n- cargo has sematic version so if you mentiont version \"0.2.3\" in carg.toml it will install minimum 0.2.3 max latest\n- use cargo build to install packages\n- use cargo update to update crates\n\t- clear\n\n","frontmatter":{"tags":"cargo rust"}},{"stats":{"dev":16777231,"mode":33188,"nlink":1,"uid":501,"gid":20,"rdev":0,"blksize":4096,"ino":106901309,"size":1372,"blocks":8,"atimeMs":1691913950931.2373,"mtimeMs":1691913950413.8467,"ctimeMs":1691913950413.8467,"birthtimeMs":1691913950413.8027,"atime":"2023-08-13T08:05:50.931Z","mtime":"2023-08-13T08:05:50.414Z","ctime":"2023-08-13T08:05:50.414Z","birthtime":"2023-08-13T08:05:50.414Z"},"slug":"notes/killua brain/CS/Rust/Gussing game","content":"\n## Function Defination\n```\nfn main() {\n    println!(\"Hello, world!\");\n}\n```\n\n## prelude\n\tThese are just small important components used in rust library\n\n\n```\nuse std::io;\nThis imports io from std library\n```\n\n```\nfn main(){\nlet mut var=String::new(); \n\n - default var are immutable so use *mut* to make it mutable\n - new is instance of String class so here var is mutable string variable\n\n```\n```\nio::stdin()\n    .read_line(&mut var)\n    .expect(\"Failed to read line\");\n\nprintln!(\"my guess is {}\",var);\n\n - stdin in part of io library\n - here read_line is the method which is taking reference of mutable variable\n - & is the reference to avoid copy\n - with some error handling\n}\n```\n\n```\nAfter downloading random crate\nuse rand::Rng; \n\nrng means random number generator\n```\n\n```\nrand::thread_rng().gen_range(1..101);\nthread_rng means creating it locally\n```\n\n```\nfor infinite loop\nloop{} \n```\n\n```\nComparing guess_no and var\n\nuse std::cmp::Ordering;\nmatch var.cmp(&guess_no){\n\tOrdering::Less=>println!(\"Lesser\"),\n\tOrdering::Equal =>{\n\t\tbreak;\n\t},\n\tOrdering::Greater=>println!(\"Greater\"),\n}\n\n```\n\n```\nExplicitly mention data type\nfloat-32 bit\nlet var:f32 = 3.2;\n\n```\n\n\n```\nlet x = (x1,x2,x3)\nx.0,x.1,x.2 gives 3 elements\n```\n\n```\nlet a:[i32;5] =[1,2,3,4,5]\nlet a=[3;5]; //here array will have 5 threes\n```\n\n- Array Indexing a[0]\n- Tuple Indexing a.0\n\n","frontmatter":{"tags":"rust"}}]